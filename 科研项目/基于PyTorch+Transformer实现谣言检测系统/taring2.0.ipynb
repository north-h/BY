{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:14:15.387302Z",
     "start_time": "2025-06-09T13:14:15.379301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import optim\n",
    "from torchnet import meter\n",
    "from tqdm import tqdm"
   ],
   "id": "5f4dda150ba3cfbf",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:14:15.423370Z",
     "start_time": "2025-06-09T13:14:15.417374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 模型输入参数，需要自己根据需要调整\n",
    "hidden_dim = 100  # 隐层大小\n",
    "epochs = 10  # 迭代次数\n",
    "batch_size = 32  # 每个批次样本大小\n",
    "embedding_dim = 20  # 每个字形成的嵌入向量大小\n",
    "output_dim = 2  # 输出维度，因为是二分类\n",
    "lr = 0.001  # 学习率\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "input_shape = 180  # 每句话的词的个数，如果不够需要使用0进行填充"
   ],
   "id": "db9e9fb293f81965",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:14:15.462398Z",
     "start_time": "2025-06-09T13:14:15.455461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载文本数据\n",
    "def load_data(file_path, input_shape=20):\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "    df = df.dropna(subset=['text'])  # 删除text为空的行\n",
    "    df['text'] = df['text'].astype(str)  # 确保所有text都是字符串\n",
    "    # 标签及词汇表\n",
    "    labels, vocabulary = list(df['label'].unique()), list(df['text'].unique())\n",
    "\n",
    "    # 构造字符级别的特征\n",
    "    string = ''\n",
    "    for word in vocabulary:\n",
    "        string += word\n",
    "\n",
    "    # 所有的词汇表\n",
    "    vocabulary = set(string)\n",
    "\n",
    "    # word2idx 将字映射为索引\n",
    "    word_dictionary = {word: i + 1 for i, word in enumerate(vocabulary)}\n",
    "    with open('word_dict.pk', 'wb') as f:\n",
    "        pickle.dump(word_dictionary, f)\n",
    "    # idx2word 将索引映射为字\n",
    "    inverse_word_dictionary = {i + 1: word for i, word in enumerate(vocabulary)}\n",
    "    # label2idx 将正反面映射为0和1\n",
    "    label_dictionary = {label: i for i, label in enumerate(labels)}\n",
    "    with open('label_dict.pk', 'wb') as f:\n",
    "        pickle.dump(label_dictionary, f)\n",
    "    # idx2label 将0和1映射为正反面\n",
    "    output_dictionary = {i: labels for i, labels in enumerate(labels)}\n",
    "\n",
    "    # 训练数据中所有词的个数\n",
    "    vocab_size = len(word_dictionary.keys())  # 词汇表大小\n",
    "    # 标签类别，分别为正、反面\n",
    "    label_size = len(label_dictionary.keys())  # 标签类别数量\n",
    "\n",
    "    # 序列填充，按input_shape填充，长度不足的按0补充\n",
    "    # 将一句话映射成对应的索引 [0,24,63...]\n",
    "    x = [[word_dictionary[word] for word in sent] for sent in df['text']]\n",
    "    # 如果长度不够input_shape，使用0进行填充\n",
    "    x = pad_sequences(maxlen=input_shape, sequences=x, padding='post', value=0)\n",
    "    # 形成标签0和1\n",
    "    y = [[label_dictionary[sent]] for sent in df['label']]\n",
    "    #     y = [np_utils.to_categorical(label, num_classes=label_size) for label in y]\n",
    "    y = np.array(y)\n",
    "\n",
    "    return x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary"
   ],
   "id": "42ed3b55f39925b3",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:14:15.475470Z",
     "start_time": "2025-06-09T13:14:15.469403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=128):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # 初始化Shape为(max_len, d_model)的PE (positional encoding)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        # 初始化一个tensor [[0, 1, 2, 3, ...]]\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # 这里就是sin和cos括号中的内容，通过e和ln进行了变换\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        # 计算PE(pos, 2i)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 计算PE(pos, 2i+1)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 为了方便计算，在最外面在unsqueeze出一个batch\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # 如果一个参数不参与梯度下降，但又希望保存model的时候将其保存下来\n",
    "        # 这个时候就可以用register_buffer\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将x和positional encoding相加。\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ],
   "id": "7adc4681122e648e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:14:15.503296Z",
     "start_time": "2025-06-09T13:14:15.497298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_class, \n",
    "                 feedforward_dim=256, num_head=2, num_layers=2,  # 减少层数\n",
    "                 dropout=0.3, max_len=128):  # 增加dropout\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.positional_encoding = PositionalEncoding(embedding_dim, dropout, max_len)\n",
    "        \n",
    "        # 添加嵌入层dropout\n",
    "        self.embed_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            embedding_dim, num_head, feedforward_dim, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers)\n",
    "        \n",
    "        # 添加分类层前的dropout\n",
    "        self.classifier_dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(embedding_dim, num_class)\n",
    "        \n",
    "        # 添加层归一化\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.embedding(x)\n",
    "        x = self.embed_dropout(x)  # 嵌入层后添加dropout\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(axis=0)\n",
    "        x = self.layer_norm(x)  # 层归一化\n",
    "        x = self.classifier_dropout(x)  # 分类前dropout\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "94988b97cc3207d2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:14:19.368235Z",
     "start_time": "2025-06-09T13:14:15.527297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.获取训练数据\n",
    "x_train, y_train, output_dictionary_train, vocab_size_train, label_size, inverse_word_dictionary_train = load_data(\n",
    "    \"./train.tsv\", input_shape)\n",
    "x_test, y_test, output_dictionary_test, vocab_size_test, label_size, inverse_word_dictionary_test = load_data(\n",
    "    \"./test.tsv\", input_shape)\n",
    "\n",
    "idx = 0\n",
    "word_dictionary = {}\n",
    "for k, v in inverse_word_dictionary_train.items():\n",
    "    word_dictionary[idx] = v\n",
    "    idx += 1\n",
    "for k, v in inverse_word_dictionary_test.items():\n",
    "    word_dictionary[idx] = v\n",
    "    idx += 1\n",
    "\n",
    "# 3.将numpy转成tensor\n",
    "x_train = torch.from_numpy(x_train).to(torch.int32)\n",
    "y_train = torch.from_numpy(y_train).to(torch.float32)\n",
    "x_test = torch.from_numpy(x_test).to(torch.int32)\n",
    "y_test = torch.from_numpy(y_test).to(torch.float32)\n",
    "\n",
    "# 4.形成训练数据集\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "\n",
    "# 5.将数据加载成迭代器\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size,\n",
    "                                           True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size,\n",
    "                                          False)"
   ],
   "id": "eecd0f5159cf0779",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:14:19.373438Z",
     "start_time": "2025-06-09T13:14:19.369244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6.模型训练\n",
    "model = Transformer(len(word_dictionary), embedding_dim, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "Configimizer = optim.Adam(model.parameters(), lr=lr)  # 优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 多分类损失函数\n",
    "\n",
    "loss_meter = meter.AverageValueMeter()\n",
    "\n",
    "best_acc = 0  # 保存最好准确率\n",
    "best_model = None  # 保存对应最好准确率的模型参数\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 开启训练模式\n",
    "    epoch_acc = 0  # 每个epoch的准确率\n",
    "    epoch_acc_count = 0  # 每个epoch训练的样本数\n",
    "    train_count = 0  # 用于计算总的样本数，方便求准确率\n",
    "    loss_meter.reset()\n",
    "    print('\\n')\n",
    "    train_bar = tqdm(train_loader)  # 形成进度条\n",
    "    for data in train_bar:\n",
    "        x_train, y_train = data  # 解包迭代器中的X和Y\n",
    "\n",
    "        x_input = x_train.long().contiguous()\n",
    "        x_input = x_input.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        Configimizer.zero_grad()\n",
    "\n",
    "        # 形成预测结果\n",
    "        output_ = model(x_input)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(output_, y_train.long().view(-1))\n",
    "        loss.backward()\n",
    "        Configimizer.step()\n",
    "\n",
    "        loss_meter.add(loss.item())\n",
    "\n",
    "        # 计算每个epoch正确的个数\n",
    "        epoch_acc_count += (output_.argmax(axis=1) == y_train.view(-1)).sum()\n",
    "        train_count += len(x_train)\n",
    "\n",
    "    # 每个epoch对应的准确率\n",
    "    epoch_acc = epoch_acc_count / train_count\n",
    "\n",
    "    # 打印信息\n",
    "    print(\"【EPOCH: 】%s\" % str(epoch + 1))\n",
    "    print(\"训练损失为%s\" % (str(loss_meter.mean)))\n",
    "    print(\"训练精度为%s\" % (str(epoch_acc.item() * 100)[:5]) + '%')\n",
    "    \n",
    "    \n",
    "    # 保存模型及相关信息\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = model.state_dict()\n",
    "\n",
    "    # 在训练结束保存最优的模型参数\n",
    "    if epoch == epochs - 1:\n",
    "        # 保存模型\n",
    "        torch.save(best_model, './best_model.pkl')"
   ],
   "id": "bbd7626a8dc2c939",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 7. 在测试集上评估模型性能\n",
    "model.load_state_dict(torch.load('./best_model.pkl'))\n",
    "model.eval()  # 设置模型为评估模式\n",
    "test_acc = 0\n",
    "test_count = 0\n",
    "\n",
    "with torch.no_grad():  # 不计算梯度，节省内存\n",
    "    test_bar = tqdm(test_loader, desc='测试进度')\n",
    "    for data in test_bar:\n",
    "        x_test, y_test = data\n",
    "        x_test = x_test.long().to(device)\n",
    "        y_test = y_test.to(device).view(-1)  # 确保标签形状正确\n",
    "        \n",
    "        output = model(x_test)\n",
    "        pred = output.argmax(dim=1)\n",
    "        \n",
    "        correct = (pred == y_test).sum().item()\n",
    "        test_acc += correct\n",
    "        test_count += len(y_test)\n",
    "        \n",
    "        # 更新进度条信息\n",
    "        test_bar.set_postfix(acc=f'{test_acc/test_count:.4f}')\n",
    "\n",
    "test_accuracy = test_acc / test_count\n",
    "print(f'\\n测试集准确率: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# 8. 对单条语句进行预测\n",
    "def predict_sentence(model, sentence, word2idx, max_len=180):\n",
    "    # 预处理输入句子\n",
    "    sequence = [word2idx.get(char, 0) for char in sentence]  # 0表示未知字符\n",
    "    sequence = pad_sequences([sequence], maxlen=max_len, padding='post', value=0)\n",
    "    tensor = torch.LongTensor(sequence).to(device)\n",
    "\n",
    "    # 模型预测\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        prediction = output.argmax(dim=1).item()\n",
    "\n",
    "    return prediction, probabilities.cpu().numpy()[0]\n",
    "\n",
    "# 创建字符到索引的映射\n",
    "word2idx = {}\n",
    "for char, idx in word_dictionary.items():\n",
    "    word2idx[char] = idx\n",
    "\n",
    "label_dict = {0: \"非谣言\", 1: \"谣言\"}\n",
    "\n",
    "# 测试不同语句\n",
    "test_sentences = [\n",
    "    \"电视刚安装好，说实话，画质不怎么样，很差！\",\n",
    "    \"你应该知道的100个中国文学常识!\",\n",
    "    \"科学研究表明每天喝8杯水有益健康\",\n",
    "    \"最新消息：下周将有三颗小行星撞击地球\"\n",
    "]\n",
    "\n",
    "print(\"\\n单条语句预测结果:\")\n",
    "for sent in test_sentences:\n",
    "    try:\n",
    "        pred, probs = predict_sentence(model, sent, word2idx)\n",
    "        print(f\"语句: '{sent}'\")\n",
    "        print(f\"预测结果: {label_dict[pred]} (置信度: {probs[pred]:.4f})\")\n",
    "        print(f\"详细概率: 非谣言={probs[0]:.4f}, 谣言={probs[1]:.4f}\")\n",
    "        print(\"-\" * 60)\n",
    "        print('\\n')\n",
    "    except KeyError:\n",
    "        print(f\"语句包含不在词汇表中的字符: '{sent}'\")"
   ],
   "id": "bc9730b89950fb54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a970779245b16df4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4705e9441da1c0f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
